\documentclass[12 pt]{article}         
\usepackage{amsfonts, amssymb}
\usepackage{fancyhdr}
\usepackage{amsmath}
\usepackage{fancyhdr}
\usepackage{verbatimbox}
\usepackage{tikz}
\usetikzlibrary{automata, positioning}

\oddsidemargin=-0.5cm                  
\setlength{\textwidth}{6.5in}          
\addtolength{\voffset}{-20pt}        		
\addtolength{\headsep}{25pt}

\setlength{\headheight}{27.2pt}
\addtolength{\topmargin}{-12.7pt}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{Theory and Practice of Algorithms \\ Homework 6}
\fancyhead[R]{Jingheng Huan \\ \today}
\fancyfoot[C]{\thepage}

\begin{document}

\section*{Problem 1}

(a) True. The dominant term in the polynomial is $2n^3$. As n approaches infinity, the lower-degree terms $(-8n^2 + 32n + 9)$ become negligible in comparison to $2n^3$. Also, we have: $2n^3 - 8n^2 + 32n + 9 \leq C \cdot n^3 \quad$ \text{for some constant } C \text{ and sufficiently large } n.

(b) True. For any real  $p \geq 0$ ,  $n^p$  is a polynomial function, and  $e^n$  is an exponential function. Exponential functions grow faster than any polynomial function. When $n \to \infty$, we have $\lim_{n \to \infty} \frac{n^p}{e^n} = 0$. There exists a constant  $C > 0$  and  $n_0 > 0$  such that for all  $n > n_0$ , we have  $n^p \leq C \cdot e^n$. This implies that  $n^p$  grows slower than  $e^n$.

(c) False. For any real  $p \geq 0$ , as  $n \to \infty$ :
$\lim_{n \to \infty} \frac{e^n}{n^p} = \infty$. This means  $e^n$  grows faster than  $n^p$  and is not bounded above by  $n^p$  multiplied by any constant.

(d) False. The function  $\sqrt{n}$  increases without bound as  $n \to \infty$ , although it grows slower than linear functions. Since  O(1)  represents constant functions that do not grow with  n , and  $\sqrt{n}$  does grow with  n , we have  $\sqrt{n} \notin O(1)$ .

\vspace{1cm}

\section*{Problem 2}
We need to show that there exist positive constants $c_1$, $c_2$, and $n_0$ such that for all $n \geq n_0$: $c_1 n^y \leq (n + x)^y \leq c_2 n^y$. Since x and y are constants and y $>$ 0, we can consider n becomes large.

For the Upper Bound: For $n \geq 1$, we have $(n + x)^y \leq (n + |x|)^y \leq n^y (1 + \frac{|x|}{n})^y$. Using the inequality $(1 + \varepsilon)^y \leq e^{y\varepsilon}$ for $\varepsilon \geq 0$, we get: $(1 + \frac{|x|}{n})^y \leq e^{y \cdot \frac{|x|}{n}} \leq e^{y|x|}$. Thus, we have $(n + x)^y \leq n^y \cdot e^{y|x|} = C_2 n^y$, where $C_2 = e^{y|x|}$ is a constant.

For the Lower Bound: For sufficiently large $n$, we have $(n + x)^y \geq (n - |x|)^y = n^y \left(1 - \frac{|x|}{n}\right)^y$. By using the inequality $(1 - \varepsilon)^y \geq 1 - y\varepsilon$ for $0 < \varepsilon < 1$ and $y > 0$: $\left(1 - \frac{|x|}{n}\right)^y \geq 1 - y \cdot \frac{|x|}{n}$. Therefore, $(n + x)^y \geq n^y \left(1 - \frac{y|x|}{n}\right) \geq n^y \left(1 - \frac{y|x|}{n_0}\right) = C_1 n^y$, for $n \geq n_0$, where $C_1 = 1 - \frac{y|x|}{n_0}$ is positive when $n_0 > y|x|$.

We can say that there exist constants $C_1 > 0$ and $C_2 > 0$ such that: $C_1 n^y \leq (n + x)^y \leq C_2 n^y$, which means that
$(n + x)^y = \Theta(n^y)$.

\vspace{1cm}

\section*{Problem 3}
(a) Applying the Master Theorem for recurrences of the form:

\[
T(n) = a\, T\left( \dfrac{n}{b} \right) + f(n)
\]

We have a = 16, b = 4, f(n) = $n^2$. Then let's compute $\log_b a$:

\[
\log_b a = \log_4 16 = 2
\]
We need to compare f(n) with $n^{\log_b a}$: $f(n) = n^2$ and $n^{\log_b a} = n^{2}$. Since f(n) = $\Theta\left( n^{\log_b a} \right)$, we are in Case 2 of the Master Theorem, then we have:

\[
T(n) = \Theta\left( n^{\log_b a} \cdot \log n \right) = \Theta\left( n^2 \log n \right)
\]

(b) Applying the Master Theorem for recurrences of the form:

\[
T(n) = a\, T\left( \dfrac{n}{b} \right) + f(n)
\]

We have a = 2, b = 4, f(n) = $n^{1/2}$. Then let's compute $\log_b a$:

\[
\log_b a = \log_4 2 = \dfrac{1}{2}
\]

Since $f(n) = \Theta\left( n^{\log_b a} \right)$, we are in Case 2. Then we have $T(n) = \Theta\left( n^{\log_b a} \cdot \log n \right) = \Theta\left( n^{1/2} \log n \right)$.


(c) The recurrence reduces  n  by 2 each time, we expand the recurrence by repeatedly substituting:

\[
T(n) = T(n - 2) + n^2 \\
= T(n - 4) + (n - 2)^2 + n^2 \\
= T(n - 6) + (n - 4)^2 + (n - 2)^2 + n^2 \\
= T(k) + \sum_{i=0}^{t} (n - 2i)^2
\]

k  is a small constant, and  t  is  n/2 . The sum  S  is: $S = \sum_{i=0}^{t} (n - 2i)^2$

This sum consists of approximately  n/2  terms of decreasing squares starting from  $n^2$  down to a constant. The sum of squares of the first  m  positive integers is  $\sum_{k=1}^{m} k^2 = \frac{m(m + 1)(2m + 1)}{6}$. However, our sum is similar to summing squares from  n  down to a small number. To estimate  S , we can consider it proportional to  $n^3$ : $S \approx \int_{0}^{n/2} (n - 2x)^2 \, dx$. Then let's compute the integral:

\[
S \approx \int_{0}^{n/2} (n - 2x)^2 \, dx \\
= \left[ (n - 2x)^3 / (-6) \right]_0^{n/2} \\
= \left( 0 - \frac{n^3}{6} \right) = \frac{n^3}{6}
\]

The total sum  S  is proportional to  $n^3$ , so: $T(n) = T(k) + S = \Theta(n^3)$



\vspace{1cm}

\noindent\textbf{Collaborators: None}

\end{document}